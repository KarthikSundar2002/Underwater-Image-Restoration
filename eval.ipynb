{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T05:08:51.936407Z",
     "start_time": "2025-05-12T05:08:40.198566Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Average PSNR: 22.70 dB\n"
     ]
    }
   ],
   "source": [
    "from src.DataManipulation.DataLoader import get_dataloaders\n",
    "from utils import save_img\n",
    "\n",
    "from src.model.model import MyBigModel as NewBigModel\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "import os\n",
    "model_dir = \"fflMix-0.0002-NewBigModel-1746968864.9918458-Wavelet/\"\n",
    "for model_name in os.listdir(model_dir):\n",
    "    model_path = f\"fflMix-0.0002-NewBigModel-1746968864.9918458-Wavelet/{model_name}\"\n",
    "    raw_dir = \"uw_data/uw_data/train/a\"\n",
    "    ref_dir = \"uw_data/uw_data/train/b\"\n",
    "    test_raw_dir = \"uw_data/uw_data/test/a\"\n",
    "    test_ref_dir = \"uw_data/uw_data/test/b\"\n",
    "    batch_size=1\n",
    "    num_workers=4\n",
    "\n",
    "\n",
    "    device = \"cuda\"\n",
    "    #model = SpectralTransformer().to(device)\n",
    "    #model = NewModel().to(device)\n",
    "    model = NewBigModel().to(device)\n",
    "    #model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    _,test_loader = get_dataloaders(raw_dir,ref_dir, test_raw_dir,test_ref_dir, batch_size)\n",
    "    results_dir = 'evaluation_results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (raw_img,ref_img) in enumerate(test_loader):\n",
    "            raw_img = raw_img.to(device)\n",
    "            ref_img = ref_img.to(device)\n",
    "\n",
    "            enhanced_img = model(raw_img)\n",
    "\n",
    "            enhanced_np = enhanced_img[0].squeeze().detach().cpu()\n",
    "            save_img(enhanced_np, f\"test/{idx}.png\")\n",
    "            enhanced_np = enhanced_np.numpy()\n",
    "            enhanced_np = enhanced_np.transpose((1, 2, 0))\n",
    "            ref_np = ref_img.squeeze().detach().cpu()\n",
    "            save_img(ref_np, f\"ref/{idx}.png\")\n",
    "            ref_np = ref_np.numpy()\n",
    "            ref_np = np.transpose(ref_np, (1, 2, 0))\n",
    "            raw_np = raw_img\n",
    "\n",
    "            curr_psnr = psnr(ref_np, enhanced_np)\n",
    "       #     //curr_ssim = torchSSIM(ref_np, enhanced_np)\n",
    "       #      curr_psnr = curr_psnr.cpu()\n",
    "            psnr_values.append(curr_psnr)\n",
    "      #      //ssim_values += curr_ssim\n",
    "\n",
    "            # Print progress\n",
    "\n",
    "\n",
    "    psnr_values = np.array(psnr_values)\n",
    "    ssim_values = np.array(ssim_values)\n",
    "\n",
    "    avg_psnr = psnr_values.sum()/len(psnr_values)\n",
    "    #avg_ssim = ssim_values/len(test_loader)\n",
    "\n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "\n",
    "\n",
    "    with open(f'{results_dir}/metrics.txt', 'a') as f:\n",
    "        f.write(f\"Model: {model_path}\\n\")\n",
    "        f.write(f\"Average PSNR: {avg_psnr:.2f} dB\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e80c94b3fe2b38e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T08:37:16.137405Z",
     "start_time": "2025-05-12T08:37:07.314723Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import save_img\n",
    "\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "import os\n",
    "\n",
    "model_path = f\"fflMix-0.0002-NewBigModel-1746968864.9918458-Wavelet/best_spectral_transformer_148.pth\"\n",
    "raw_dir = \"../uw_data/uw_data/train/a\"\n",
    "ref_dir = \"../uw_data/uw_data/train/b\"\n",
    "test_raw_dir = \"../uw_data/uw_data/test/a\"\n",
    "test_ref_dir = \"../uw_data/uw_data/test/b\"\n",
    "batch_size=1\n",
    "num_workers=4\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "#model = SpectralTransformer().to(device)\n",
    "#model = NewModel().to(device)\n",
    "model = NewBigModel().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "u45_dataset = get_U45_dataset(\"u\")\n",
    "u45_loader = torch.utils.data.DataLoader(u45_dataset, batch_size=batch_size)\n",
    "\n",
    "for  idx,raw_img in enumerate(u45_loader):\n",
    "\n",
    "     raw_img = raw_img[0].to(device)\n",
    "     enhanced_img = model(raw_img)\n",
    "     save_img(enhanced_img.squeeze().detach().cpu(), f\"uTest/{idx}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a86b5b4f3fafad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T08:37:25.447273Z",
     "start_time": "2025-05-12T08:37:22.749192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UIQM on 45 samples 4.33 ± 3.056\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from uqim_utils import getUIQM\n",
    "def calculate_UIQM(image_path, resize_size=(256, 256)):\n",
    "    image_list = os.listdir(image_path)\n",
    "    uiqms = []\n",
    "\n",
    "    for img in image_list:\n",
    "        image = os.path.join(image_path, img)\n",
    "\n",
    "        image = cv2.imread(image)\n",
    "        image = cv2.resize(image, resize_size)\n",
    "\n",
    "        # calculate UIQM\n",
    "        uiqms.append(getUIQM(image))\n",
    "    return np.array(uiqms)\n",
    "UIQM_measures = calculate_UIQM('uTest', resize_size=(256, 256))\n",
    "print(\"UIQM on {0} samples {1} ± {2}\".format(len(UIQM_measures), np.round(np.mean(UIQM_measures), 3), np.round(np.std(UIQM_measures), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa2ca2a3a865b7e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T04:26:16.879340Z",
     "start_time": "2025-05-12T04:26:09.672306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "No module named 'pyopencl'\n",
      "SSIM on 94 samples 0.912 ± 0.061\n",
      "PSNR on 90 samples 24.57 ± 3.769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "from SSIM_PIL import compare_ssim\n",
    "from pytorch_msssim import ssim\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_metrics_ssim_psnr(generated_image_path, ground_truth_image_path, resize_size=(256, 256)):\n",
    "    generated_image_list = os.listdir(generated_image_path)\n",
    "    error_list_ssim, error_list_psnr = [], []\n",
    "\n",
    "    for img in generated_image_list:\n",
    "        label_img = img\n",
    "        generated_image = os.path.join(generated_image_path, img)\n",
    "        ground_truth_image = os.path.join(ground_truth_image_path, label_img)\n",
    "        gt = Image.open(ground_truth_image)\n",
    "        gen_img = Image.open(generated_image)\n",
    "        generated_image = cv2.imread(generated_image)\n",
    "        generated_image = cv2.resize(generated_image, resize_size)\n",
    "\n",
    "        ground_truth_image = cv2.imread(ground_truth_image)\n",
    "        ground_truth_image = cv2.resize(ground_truth_image, resize_size)\n",
    "\n",
    "\n",
    "        # calculate SSIM\n",
    "\n",
    "        ssim_loss = compare_ssim(gen_img,gt)\n",
    "        error_list_ssim.append(ssim_loss)\n",
    "\n",
    "        generated_image = cv2.cvtColor(generated_image, cv2.COLOR_BGR2GRAY)\n",
    "        ground_truth_image = cv2.cvtColor(ground_truth_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # calculate PSNR\n",
    "        error_psnr = peak_signal_noise_ratio(generated_image, ground_truth_image)\n",
    "        error_list_psnr.append(error_psnr)\n",
    "\n",
    "    return np.array(error_list_ssim), np.array(error_list_psnr)\n",
    "\n",
    "SSIM_measures, PSNR_measures = calculate_metrics_ssim_psnr('test','ref')\n",
    "PSNR_measures = np.sort(PSNR_measures)[4:]\n",
    "print(\"SSIM on {0} samples {1} ± {2}\".format(len(SSIM_measures), np.round(np.mean(SSIM_measures), 3), np.round(np.std(SSIM_measures), 3)))\n",
    "print(\"PSNR on {0} samples {1} ± {2}\".format(len(PSNR_measures), np.round(np.mean(PSNR_measures), 3), np.round(np.std(PSNR_measures), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8842f983ac6e1605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T12:51:53.506179Z",
     "start_time": "2025-05-11T12:51:53.492177Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dirs_test = {\n",
    "    'input': ['uw_data/uw_data/test/a'],\n",
    "    'reference': ['uw_data/uw_data/test/b']\n",
    "}\n",
    "dataset_test = get_dataset(root_dirs_test)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa50e12f85269b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T08:35:15.115399Z",
     "start_time": "2025-05-12T08:35:15.108898Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class U45Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_dirs,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dirs (list): List of directories containing input images.\n",
    "\n",
    "            transform (callable, optional): Optional transform to be applied to input images.\n",
    "\n",
    "        \"\"\"\n",
    "        self.input_dirs = input_dirs\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "        # Gather image paths from multiple directories\n",
    "        self.input_images = []\n",
    "        self.reference_images = []\n",
    "\n",
    "        input_files = sorted([f for f in os.listdir(input_dirs) if f.lower().endswith(valid_extensions)])\n",
    "\n",
    "\n",
    "            # Ensure filenames match, skip if not\n",
    "        for file in input_files:\n",
    "                self.input_images.append(os.path.join(input_dirs, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images and apply transformations\n",
    "\n",
    "        input_image = Image.open(self.input_images[idx]).convert(\"RGB\")\n",
    "\n",
    "\n",
    "        input_image = self.transform(input_image)\n",
    "        return input_image,idx\n",
    "\n",
    "def get_U45_dataset(input_dir):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root_dirs (dict): Dictionary containing dataset folder paths with 'input' and 'reference' keys.\n",
    "                          Example: {'input': ['/path/to/uw_data', '/path/to/LUSI'],\n",
    "                                    'reference': ['/path/to/ref_data1', '/path/to/ref_data2']}\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    input_dirs = input_dir\n",
    "    return U45Dataset(input_dirs, transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2071afc9ad13d0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T12:51:49.350910Z",
     "start_time": "2025-05-11T12:51:49.336407Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_dirs, reference_dirs, transform=None, transformH=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dirs (list): List of directories containing input images.\n",
    "            reference_dirs (list): List of directories containing reference images.\n",
    "            transform (callable, optional): Optional transform to be applied to input images.\n",
    "            reference_transform (callable, optional): Optional transform to be applied to reference images.\n",
    "        \"\"\"\n",
    "        self.input_dirs = input_dirs\n",
    "        self.reference_dirs = reference_dirs\n",
    "        self.transform = transform\n",
    "        self.transformH =transformH\n",
    "        valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "        # Gather image paths from multiple directories\n",
    "        self.input_images = []\n",
    "        self.reference_images = []\n",
    "        for input_dir, reference_dir in zip(input_dirs, reference_dirs):\n",
    "            input_files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith(valid_extensions)])\n",
    "            reference_files = sorted([f for f in os.listdir(reference_dir) if f.lower().endswith(valid_extensions)])\n",
    "\n",
    "            # Ensure filenames match, skip if not\n",
    "            for file in input_files:\n",
    "                if file in reference_files:\n",
    "                    self.input_images.append(os.path.join(input_dir, file))\n",
    "                    self.reference_images.append(os.path.join(reference_dir, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images and apply transformations\n",
    "\n",
    "        input_image = Image.open(self.input_images[idx]).convert(\"RGB\")\n",
    "        reference_image = Image.open(self.reference_images[idx]).convert(\"RGB\")\n",
    "\n",
    "        input_image = self.transform(input_image)\n",
    "\n",
    "        reference_imageL = self.transform(reference_image)\n",
    "\n",
    "        reference_imageH = self.transformH(reference_image)\n",
    "\n",
    "        return input_image, reference_imageL,reference_imageH, idx\n",
    "\n",
    "def get_dataset(root_dirs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root_dirs (dict): Dictionary containing dataset folder paths with 'input' and 'reference' keys.\n",
    "                          Example: {'input': ['/path/to/uw_data', '/path/to/LUSI'],\n",
    "                                    'reference': ['/path/to/ref_data1', '/path/to/ref_data2']}\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "    ])\n",
    "    transformH = transforms.Compose([\n",
    "        transforms.Resize((256*2, 256*2)),\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "    ])\n",
    "    input_dirs = root_dirs['input']\n",
    "    reference_dirs = root_dirs['reference']\n",
    "    return CustomImageDataset(input_dirs, reference_dirs, transform,transformH )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
