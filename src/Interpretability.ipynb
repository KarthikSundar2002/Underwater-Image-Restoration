{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-03T21:48:48.811227Z",
     "start_time": "2025-05-03T21:48:48.785227Z"
    }
   },
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from src.model.model import MyModel\n",
    "import torch\n",
    "\n",
    "\n",
    "weights_path = \"../netG_model_epoch_1.pth\"\n",
    "model = torch.load(weights_path)"
   ],
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001B[1mdo those steps only if you trust the source of the checkpoint\u001B[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL newmodel.model.MyBigModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([MyBigModel])` or the `torch.serialization.safe_globals([MyBigModel])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 10\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      9\u001B[0m weights_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../netG_model_epoch_1.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 10\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Underwater-Image-Restoration\\.venv\\lib\\site-packages\\torch\\serialization.py:1470\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1462\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[0;32m   1463\u001B[0m                     opened_zipfile,\n\u001B[0;32m   1464\u001B[0m                     map_location,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1467\u001B[0m                     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[0;32m   1468\u001B[0m                 )\n\u001B[0;32m   1469\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1470\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1471\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[0;32m   1472\u001B[0m             opened_zipfile,\n\u001B[0;32m   1473\u001B[0m             map_location,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1476\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[0;32m   1477\u001B[0m         )\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n",
      "\u001B[1;31mUnpicklingError\u001B[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001B[1mdo those steps only if you trust the source of the checkpoint\u001B[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL newmodel.model.MyBigModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([MyBigModel])` or the `torch.serialization.safe_globals([MyBigModel])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T14:58:56.013492Z",
     "start_time": "2025-05-03T14:58:56.002493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_names = []\n",
    "def get_layer_names(model):\n",
    "    for name, module in model.named_modules():\n",
    "        layer_names.append(name)\n",
    "    return layer_names\n",
    "\n",
    "get_layer_names(model)"
   ],
   "id": "e9cdfdd542c46121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'input_proj',\n",
       " 'input_proj.proj',\n",
       " 'input_proj.proj.0',\n",
       " 'input_proj.proj.1',\n",
       " 'pos_drop',\n",
       " 'encoder_0',\n",
       " 'encoder_0.drop_path',\n",
       " 'encoder_0.norm1',\n",
       " 'encoder_0.mlp',\n",
       " 'encoder_0.mlp.linear1',\n",
       " 'encoder_0.mlp.linear1.0',\n",
       " 'encoder_0.mlp.linear1.1',\n",
       " 'encoder_0.mlp.dwconv',\n",
       " 'encoder_0.mlp.dwconv.0',\n",
       " 'encoder_0.mlp.dwconv.1',\n",
       " 'encoder_0.mlp.linear2',\n",
       " 'encoder_0.mlp.linear2.0',\n",
       " 'encoder_0.mlp.eca',\n",
       " 'encoder_0.norm2',\n",
       " 'encoder_0.freq_mlp',\n",
       " 'encoder_0.freq_mlp.linear1',\n",
       " 'encoder_0.freq_mlp.linear1.0',\n",
       " 'encoder_0.freq_mlp.linear1.1',\n",
       " 'encoder_0.freq_mlp.dwconv',\n",
       " 'encoder_0.freq_mlp.dwconv.0',\n",
       " 'encoder_0.freq_mlp.dwconv.1',\n",
       " 'encoder_0.freq_mlp.linear2',\n",
       " 'encoder_0.freq_mlp.linear2.0',\n",
       " 'encoder_0.freq_mlp.eca',\n",
       " 'encoder_0.drop_path2',\n",
       " 'downsample_0',\n",
       " 'downsample_0.conv',\n",
       " 'encoder_1',\n",
       " 'encoder_1.drop_path',\n",
       " 'encoder_1.norm1',\n",
       " 'encoder_1.mlp',\n",
       " 'encoder_1.mlp.linear1',\n",
       " 'encoder_1.mlp.linear1.0',\n",
       " 'encoder_1.mlp.linear1.1',\n",
       " 'encoder_1.mlp.dwconv',\n",
       " 'encoder_1.mlp.dwconv.0',\n",
       " 'encoder_1.mlp.dwconv.1',\n",
       " 'encoder_1.mlp.linear2',\n",
       " 'encoder_1.mlp.linear2.0',\n",
       " 'encoder_1.mlp.eca',\n",
       " 'encoder_1.norm2',\n",
       " 'encoder_1.freq_mlp',\n",
       " 'encoder_1.freq_mlp.linear1',\n",
       " 'encoder_1.freq_mlp.linear1.0',\n",
       " 'encoder_1.freq_mlp.linear1.1',\n",
       " 'encoder_1.freq_mlp.dwconv',\n",
       " 'encoder_1.freq_mlp.dwconv.0',\n",
       " 'encoder_1.freq_mlp.dwconv.1',\n",
       " 'encoder_1.freq_mlp.linear2',\n",
       " 'encoder_1.freq_mlp.linear2.0',\n",
       " 'encoder_1.freq_mlp.eca',\n",
       " 'encoder_1.drop_path2',\n",
       " 'downsample_1',\n",
       " 'downsample_1.conv',\n",
       " 'encoder_2',\n",
       " 'encoder_2.drop_path',\n",
       " 'encoder_2.norm1',\n",
       " 'encoder_2.mlp',\n",
       " 'encoder_2.mlp.linear1',\n",
       " 'encoder_2.mlp.linear1.0',\n",
       " 'encoder_2.mlp.linear1.1',\n",
       " 'encoder_2.mlp.dwconv',\n",
       " 'encoder_2.mlp.dwconv.0',\n",
       " 'encoder_2.mlp.dwconv.1',\n",
       " 'encoder_2.mlp.linear2',\n",
       " 'encoder_2.mlp.linear2.0',\n",
       " 'encoder_2.mlp.eca',\n",
       " 'encoder_2.norm2',\n",
       " 'encoder_2.freq_mlp',\n",
       " 'encoder_2.freq_mlp.linear1',\n",
       " 'encoder_2.freq_mlp.linear1.0',\n",
       " 'encoder_2.freq_mlp.linear1.1',\n",
       " 'encoder_2.freq_mlp.dwconv',\n",
       " 'encoder_2.freq_mlp.dwconv.0',\n",
       " 'encoder_2.freq_mlp.dwconv.1',\n",
       " 'encoder_2.freq_mlp.linear2',\n",
       " 'encoder_2.freq_mlp.linear2.0',\n",
       " 'encoder_2.freq_mlp.eca',\n",
       " 'encoder_2.drop_path2',\n",
       " 'downsample_2',\n",
       " 'downsample_2.conv',\n",
       " 'encoder_3',\n",
       " 'encoder_3.drop_path',\n",
       " 'encoder_3.norm1',\n",
       " 'encoder_3.mlp',\n",
       " 'encoder_3.mlp.linear1',\n",
       " 'encoder_3.mlp.linear1.0',\n",
       " 'encoder_3.mlp.linear1.1',\n",
       " 'encoder_3.mlp.dwconv',\n",
       " 'encoder_3.mlp.dwconv.0',\n",
       " 'encoder_3.mlp.dwconv.1',\n",
       " 'encoder_3.mlp.linear2',\n",
       " 'encoder_3.mlp.linear2.0',\n",
       " 'encoder_3.mlp.eca',\n",
       " 'encoder_3.norm2',\n",
       " 'encoder_3.freq_mlp',\n",
       " 'encoder_3.freq_mlp.linear1',\n",
       " 'encoder_3.freq_mlp.linear1.0',\n",
       " 'encoder_3.freq_mlp.linear1.1',\n",
       " 'encoder_3.freq_mlp.dwconv',\n",
       " 'encoder_3.freq_mlp.dwconv.0',\n",
       " 'encoder_3.freq_mlp.dwconv.1',\n",
       " 'encoder_3.freq_mlp.linear2',\n",
       " 'encoder_3.freq_mlp.linear2.0',\n",
       " 'encoder_3.freq_mlp.eca',\n",
       " 'encoder_3.drop_path2',\n",
       " 'downsample_3',\n",
       " 'downsample_3.conv',\n",
       " 'bottleneck',\n",
       " 'bottleneck.drop_path',\n",
       " 'bottleneck.norm1',\n",
       " 'bottleneck.norm2',\n",
       " 'bottleneck.mdassa',\n",
       " 'bottleneck.mdassa.norm1',\n",
       " 'bottleneck.mdassa.norm_q',\n",
       " 'bottleneck.mdassa.norm_kv',\n",
       " 'bottleneck.mdassa.attn',\n",
       " 'bottleneck.mdassa.attn.to_qkv',\n",
       " 'bottleneck.mdassa.attn.to_qkv.to_q',\n",
       " 'bottleneck.mdassa.attn.to_qkv.to_kv_from_q',\n",
       " 'bottleneck.mdassa.attn.to_qkv.to_kv',\n",
       " 'bottleneck.mdassa.attn.attn_drop',\n",
       " 'bottleneck.mdassa.attn.proj',\n",
       " 'bottleneck.mdassa.attn.proj_drop',\n",
       " 'bottleneck.mdassa.attn.softmax',\n",
       " 'bottleneck.mdassa.attn.relu',\n",
       " 'bottleneck.mdassa.conv1x1',\n",
       " 'bottleneck.mdassa.fdfp',\n",
       " 'bottleneck.mdassa.fdfp.dwt',\n",
       " 'bottleneck.mdassa.fdfp.idwt',\n",
       " 'bottleneck.mdassa.fdfp.conv1',\n",
       " 'bottleneck.mdassa.fdfp.conv2',\n",
       " 'bottleneck.mdassa.fdfp.act',\n",
       " 'bottleneck.mdassa.freq_attn',\n",
       " 'bottleneck.mdassa.freq_attn.to_qkv',\n",
       " 'bottleneck.mdassa.freq_attn.to_qkv.to_q',\n",
       " 'bottleneck.mdassa.freq_attn.to_qkv.to_kv_from_q',\n",
       " 'bottleneck.mdassa.freq_attn.to_qkv.to_kv',\n",
       " 'bottleneck.mdassa.freq_attn.attn_drop',\n",
       " 'bottleneck.mdassa.freq_attn.proj',\n",
       " 'bottleneck.mdassa.freq_attn.proj_drop',\n",
       " 'bottleneck.mdassa.freq_attn.softmax',\n",
       " 'bottleneck.mdassa.freq_attn.relu',\n",
       " 'bottleneck.mdassa.spatial_drop_path',\n",
       " 'bottleneck.mdassa.freq_drop_path',\n",
       " 'bottleneck.mlp',\n",
       " 'bottleneck.mlp.linear1',\n",
       " 'bottleneck.mlp.linear1.0',\n",
       " 'bottleneck.mlp.linear1.1',\n",
       " 'bottleneck.mlp.dwconv',\n",
       " 'bottleneck.mlp.dwconv.0',\n",
       " 'bottleneck.mlp.dwconv.1',\n",
       " 'bottleneck.mlp.linear2',\n",
       " 'bottleneck.mlp.linear2.0',\n",
       " 'bottleneck.mlp.eca',\n",
       " 'bottleneck.mlp_proj',\n",
       " 'upsample_3',\n",
       " 'upsample_3.conv',\n",
       " 'decoder_3',\n",
       " 'decoder_3.drop_path',\n",
       " 'decoder_3.norm1',\n",
       " 'decoder_3.norm2',\n",
       " 'decoder_3.mdassa',\n",
       " 'decoder_3.mdassa.norm1',\n",
       " 'decoder_3.mdassa.norm_q',\n",
       " 'decoder_3.mdassa.norm_kv',\n",
       " 'decoder_3.mdassa.attn',\n",
       " 'decoder_3.mdassa.attn.to_qkv',\n",
       " 'decoder_3.mdassa.attn.to_qkv.to_q',\n",
       " 'decoder_3.mdassa.attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_3.mdassa.attn.to_qkv.to_kv',\n",
       " 'decoder_3.mdassa.attn.attn_drop',\n",
       " 'decoder_3.mdassa.attn.proj',\n",
       " 'decoder_3.mdassa.attn.proj_drop',\n",
       " 'decoder_3.mdassa.attn.softmax',\n",
       " 'decoder_3.mdassa.attn.relu',\n",
       " 'decoder_3.mdassa.conv1x1',\n",
       " 'decoder_3.mdassa.fdfp',\n",
       " 'decoder_3.mdassa.fdfp.dwt',\n",
       " 'decoder_3.mdassa.fdfp.idwt',\n",
       " 'decoder_3.mdassa.fdfp.conv1',\n",
       " 'decoder_3.mdassa.fdfp.conv2',\n",
       " 'decoder_3.mdassa.fdfp.act',\n",
       " 'decoder_3.mdassa.freq_attn',\n",
       " 'decoder_3.mdassa.freq_attn.to_qkv',\n",
       " 'decoder_3.mdassa.freq_attn.to_qkv.to_q',\n",
       " 'decoder_3.mdassa.freq_attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_3.mdassa.freq_attn.to_qkv.to_kv',\n",
       " 'decoder_3.mdassa.freq_attn.attn_drop',\n",
       " 'decoder_3.mdassa.freq_attn.proj',\n",
       " 'decoder_3.mdassa.freq_attn.proj_drop',\n",
       " 'decoder_3.mdassa.freq_attn.softmax',\n",
       " 'decoder_3.mdassa.freq_attn.relu',\n",
       " 'decoder_3.mdassa.spatial_drop_path',\n",
       " 'decoder_3.mdassa.freq_drop_path',\n",
       " 'decoder_3.mlp',\n",
       " 'decoder_3.mlp.linear1',\n",
       " 'decoder_3.mlp.linear1.0',\n",
       " 'decoder_3.mlp.linear1.1',\n",
       " 'decoder_3.mlp.dwconv',\n",
       " 'decoder_3.mlp.dwconv.0',\n",
       " 'decoder_3.mlp.dwconv.1',\n",
       " 'decoder_3.mlp.linear2',\n",
       " 'decoder_3.mlp.linear2.0',\n",
       " 'decoder_3.mlp.eca',\n",
       " 'decoder_3.mlp_proj',\n",
       " 'upsample_2',\n",
       " 'upsample_2.conv',\n",
       " 'decoder_2',\n",
       " 'decoder_2.drop_path',\n",
       " 'decoder_2.norm1',\n",
       " 'decoder_2.norm2',\n",
       " 'decoder_2.mdassa',\n",
       " 'decoder_2.mdassa.norm1',\n",
       " 'decoder_2.mdassa.norm_q',\n",
       " 'decoder_2.mdassa.norm_kv',\n",
       " 'decoder_2.mdassa.attn',\n",
       " 'decoder_2.mdassa.attn.to_qkv',\n",
       " 'decoder_2.mdassa.attn.to_qkv.to_q',\n",
       " 'decoder_2.mdassa.attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_2.mdassa.attn.to_qkv.to_kv',\n",
       " 'decoder_2.mdassa.attn.attn_drop',\n",
       " 'decoder_2.mdassa.attn.proj',\n",
       " 'decoder_2.mdassa.attn.proj_drop',\n",
       " 'decoder_2.mdassa.attn.softmax',\n",
       " 'decoder_2.mdassa.attn.relu',\n",
       " 'decoder_2.mdassa.conv1x1',\n",
       " 'decoder_2.mdassa.fdfp',\n",
       " 'decoder_2.mdassa.fdfp.dwt',\n",
       " 'decoder_2.mdassa.fdfp.idwt',\n",
       " 'decoder_2.mdassa.fdfp.conv1',\n",
       " 'decoder_2.mdassa.fdfp.conv2',\n",
       " 'decoder_2.mdassa.fdfp.act',\n",
       " 'decoder_2.mdassa.freq_attn',\n",
       " 'decoder_2.mdassa.freq_attn.to_qkv',\n",
       " 'decoder_2.mdassa.freq_attn.to_qkv.to_q',\n",
       " 'decoder_2.mdassa.freq_attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_2.mdassa.freq_attn.to_qkv.to_kv',\n",
       " 'decoder_2.mdassa.freq_attn.attn_drop',\n",
       " 'decoder_2.mdassa.freq_attn.proj',\n",
       " 'decoder_2.mdassa.freq_attn.proj_drop',\n",
       " 'decoder_2.mdassa.freq_attn.softmax',\n",
       " 'decoder_2.mdassa.freq_attn.relu',\n",
       " 'decoder_2.mdassa.spatial_drop_path',\n",
       " 'decoder_2.mdassa.freq_drop_path',\n",
       " 'decoder_2.mlp',\n",
       " 'decoder_2.mlp.linear1',\n",
       " 'decoder_2.mlp.linear1.0',\n",
       " 'decoder_2.mlp.linear1.1',\n",
       " 'decoder_2.mlp.dwconv',\n",
       " 'decoder_2.mlp.dwconv.0',\n",
       " 'decoder_2.mlp.dwconv.1',\n",
       " 'decoder_2.mlp.linear2',\n",
       " 'decoder_2.mlp.linear2.0',\n",
       " 'decoder_2.mlp.eca',\n",
       " 'decoder_2.mlp_proj',\n",
       " 'upsample_1',\n",
       " 'upsample_1.conv',\n",
       " 'decoder_1',\n",
       " 'decoder_1.drop_path',\n",
       " 'decoder_1.norm1',\n",
       " 'decoder_1.norm2',\n",
       " 'decoder_1.mdassa',\n",
       " 'decoder_1.mdassa.norm1',\n",
       " 'decoder_1.mdassa.norm_q',\n",
       " 'decoder_1.mdassa.norm_kv',\n",
       " 'decoder_1.mdassa.attn',\n",
       " 'decoder_1.mdassa.attn.to_qkv',\n",
       " 'decoder_1.mdassa.attn.to_qkv.to_q',\n",
       " 'decoder_1.mdassa.attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_1.mdassa.attn.to_qkv.to_kv',\n",
       " 'decoder_1.mdassa.attn.attn_drop',\n",
       " 'decoder_1.mdassa.attn.proj',\n",
       " 'decoder_1.mdassa.attn.proj_drop',\n",
       " 'decoder_1.mdassa.attn.softmax',\n",
       " 'decoder_1.mdassa.attn.relu',\n",
       " 'decoder_1.mdassa.conv1x1',\n",
       " 'decoder_1.mdassa.fdfp',\n",
       " 'decoder_1.mdassa.fdfp.dwt',\n",
       " 'decoder_1.mdassa.fdfp.idwt',\n",
       " 'decoder_1.mdassa.fdfp.conv1',\n",
       " 'decoder_1.mdassa.fdfp.conv2',\n",
       " 'decoder_1.mdassa.fdfp.act',\n",
       " 'decoder_1.mdassa.freq_attn',\n",
       " 'decoder_1.mdassa.freq_attn.to_qkv',\n",
       " 'decoder_1.mdassa.freq_attn.to_qkv.to_q',\n",
       " 'decoder_1.mdassa.freq_attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_1.mdassa.freq_attn.to_qkv.to_kv',\n",
       " 'decoder_1.mdassa.freq_attn.attn_drop',\n",
       " 'decoder_1.mdassa.freq_attn.proj',\n",
       " 'decoder_1.mdassa.freq_attn.proj_drop',\n",
       " 'decoder_1.mdassa.freq_attn.softmax',\n",
       " 'decoder_1.mdassa.freq_attn.relu',\n",
       " 'decoder_1.mdassa.spatial_drop_path',\n",
       " 'decoder_1.mdassa.freq_drop_path',\n",
       " 'decoder_1.mlp',\n",
       " 'decoder_1.mlp.linear1',\n",
       " 'decoder_1.mlp.linear1.0',\n",
       " 'decoder_1.mlp.linear1.1',\n",
       " 'decoder_1.mlp.dwconv',\n",
       " 'decoder_1.mlp.dwconv.0',\n",
       " 'decoder_1.mlp.dwconv.1',\n",
       " 'decoder_1.mlp.linear2',\n",
       " 'decoder_1.mlp.linear2.0',\n",
       " 'decoder_1.mlp.eca',\n",
       " 'decoder_1.mlp_proj',\n",
       " 'upsample_0',\n",
       " 'upsample_0.conv',\n",
       " 'decoder_0',\n",
       " 'decoder_0.drop_path',\n",
       " 'decoder_0.norm1',\n",
       " 'decoder_0.norm2',\n",
       " 'decoder_0.mdassa',\n",
       " 'decoder_0.mdassa.norm1',\n",
       " 'decoder_0.mdassa.norm_q',\n",
       " 'decoder_0.mdassa.norm_kv',\n",
       " 'decoder_0.mdassa.attn',\n",
       " 'decoder_0.mdassa.attn.to_qkv',\n",
       " 'decoder_0.mdassa.attn.to_qkv.to_q',\n",
       " 'decoder_0.mdassa.attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_0.mdassa.attn.to_qkv.to_kv',\n",
       " 'decoder_0.mdassa.attn.attn_drop',\n",
       " 'decoder_0.mdassa.attn.proj',\n",
       " 'decoder_0.mdassa.attn.proj_drop',\n",
       " 'decoder_0.mdassa.attn.softmax',\n",
       " 'decoder_0.mdassa.attn.relu',\n",
       " 'decoder_0.mdassa.conv1x1',\n",
       " 'decoder_0.mdassa.fdfp',\n",
       " 'decoder_0.mdassa.fdfp.dwt',\n",
       " 'decoder_0.mdassa.fdfp.idwt',\n",
       " 'decoder_0.mdassa.fdfp.conv1',\n",
       " 'decoder_0.mdassa.fdfp.conv2',\n",
       " 'decoder_0.mdassa.fdfp.act',\n",
       " 'decoder_0.mdassa.freq_attn',\n",
       " 'decoder_0.mdassa.freq_attn.to_qkv',\n",
       " 'decoder_0.mdassa.freq_attn.to_qkv.to_q',\n",
       " 'decoder_0.mdassa.freq_attn.to_qkv.to_kv_from_q',\n",
       " 'decoder_0.mdassa.freq_attn.to_qkv.to_kv',\n",
       " 'decoder_0.mdassa.freq_attn.attn_drop',\n",
       " 'decoder_0.mdassa.freq_attn.proj',\n",
       " 'decoder_0.mdassa.freq_attn.proj_drop',\n",
       " 'decoder_0.mdassa.freq_attn.softmax',\n",
       " 'decoder_0.mdassa.freq_attn.relu',\n",
       " 'decoder_0.mdassa.spatial_drop_path',\n",
       " 'decoder_0.mdassa.freq_drop_path',\n",
       " 'decoder_0.mlp',\n",
       " 'decoder_0.mlp.linear1',\n",
       " 'decoder_0.mlp.linear1.0',\n",
       " 'decoder_0.mlp.linear1.1',\n",
       " 'decoder_0.mlp.dwconv',\n",
       " 'decoder_0.mlp.dwconv.0',\n",
       " 'decoder_0.mlp.dwconv.1',\n",
       " 'decoder_0.mlp.linear2',\n",
       " 'decoder_0.mlp.linear2.0',\n",
       " 'decoder_0.mlp.eca',\n",
       " 'decoder_0.mlp_proj',\n",
       " 'output_proj',\n",
       " 'output_proj.proj',\n",
       " 'output_proj.proj.0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T15:02:01.693085Z",
     "start_time": "2025-05-03T15:02:01.688085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "GradCAM(model=model,target_layers=model.output_proj.proj)"
   ],
   "id": "cf0ca39f3feb1da1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_grad_cam.grad_cam.GradCAM at 0x22247ab3fa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T15:27:12.686129Z",
     "start_time": "2025-05-03T15:27:12.669515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImageEnhancementTarget:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        return (model_output).sum()"
   ],
   "id": "4215b55bccd8c3ad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T17:29:04.288501Z",
     "start_time": "2025-05-03T17:29:01.353327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import torch\n",
    "import numpy as np\n",
    "inp_image_path = \"../data/uw_data/uw_data/manipulated/1imagea/6_img_.png\"\n",
    "\n",
    "image = Image.open(inp_image_path)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "inp = transform(image)\n",
    "\n",
    "inp = inp.unsqueeze_(0)\n",
    "print(inp.shape)\n",
    "model.eval()\n",
    "out = model(inp)\n",
    "o = out.detach().numpy()\n",
    "\n",
    "o = o.squeeze()\n",
    "o = o.transpose(1, 2, 0)\n",
    "o = np.clip(o, 0, 1)\n",
    "o = o*255\n",
    "o = o.astype('uint8')\n",
    "print(o.shape)\n",
    "Image.fromarray(o).convert('RGB').show()\n",
    "targets = [ImageEnhancementTarget()]\n",
    "print(targets)\n",
    "cam = GradCAM(model=model,target_layers=model.output_proj.proj)\n",
    "\n",
    "gray_cam = cam(input_tensor=inp, targets=targets)[0, :]\n",
    "rgb_image = inp[0].detach().numpy()\n",
    "rgb_image = rgb_image.transpose((1, 2, 0))\n",
    "\n",
    "cam_image = show_cam_on_image(rgb_image,gray_cam,use_rgb=True)\n",
    "print(cam_image.shape)\n",
    "Image.fromarray(cam_image).convert(\"RGB\").show()"
   ],
   "id": "21759fa866765b73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "(256, 256, 3)\n",
      "[<__main__.ImageEnhancementTarget object at 0x000001593F234250>]\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
