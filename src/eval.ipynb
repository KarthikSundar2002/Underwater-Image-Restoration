{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f633fc7ada03594b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T10:11:15.362907Z",
     "start_time": "2025-05-11T10:11:15.109847Z"
    }
   },
   "source": [
    "from numpy import sort\n",
    "from src.Models.SpectralTransformer import SpectralTransformer\n",
    "from src.model.model import MyModel as NewModel\n",
    "from src.model.model import MyBigModel as NewBigModel\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "from src.DataManipulation.DataLoader import get_dataloaders\n",
    "import os\n",
    "\n",
    "model_path = \"../best.pth\"\n",
    "raw_dir = \"../uw_data/uw_data/train/a\"\n",
    "ref_dir = \"../uw_data/uw_data/train/b\"\n",
    "test_raw_dir = \"../uw_data/uw_data/test/a\"\n",
    "test_ref_dir = \"../uw_data/uw_data/test/b\"\n",
    "batch_size=1\n",
    "num_workers=4\n",
    "_, test_loader = get_dataloaders(raw_dir,ref_dir,test_raw_dir,test_ref_dir,batch_size=batch_size,num_workers=num_workers)\n",
    "\n",
    "device = \"cuda\"\n",
    "model = SpectralTransformer().to(device)\n",
    "#model = NewModel().to(device)\n",
    "#model = NewBigModel().to(device)\n",
    "#checkpoint = torch.load(model_path, map_location=device)\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model.eval()\n",
    "\n",
    "psnr_values = []\n",
    "ssim_values = 0\n",
    "\n",
    "results_dir = 'evaluation_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (raw_img, ref_img) in enumerate(test_loader):\n",
    "        raw_img = raw_img.to(device)\n",
    "        ref_img = ref_img.to(device)\n",
    "\n",
    "        enhanced_img = model(raw_img)\n",
    "\n",
    "        enhanced_np = enhanced_img[0].squeeze().detach().cpu().numpy()\n",
    "        enhanced_np = enhanced_np.transpose((1, 2, 0))\n",
    "        ref_np = ref_img.squeeze().detach().cpu().numpy()\n",
    "        ref_np = np.transpose(ref_np, (1, 2, 0))\n",
    "        raw_np = raw_img\n",
    "        print(\"enhanced_np.shape:\", enhanced_np.shape)\n",
    "        print(\"ref_np.shape:\", ref_np.shape)\n",
    "        curr_psnr = psnr(ref_np, enhanced_np)\n",
    "        # curr_ssim = torchSSIM(ref_np, enhanced_np)\n",
    "        # curr_psnr = curr_psnr.cpu()\n",
    "        psnr_values.append(curr_psnr)\n",
    "        # ssim_values += curr_ssim\n",
    "\n",
    "        # Print progress\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(test_loader)} test images\")\n",
    "\n",
    "psnr_values = np.array(psnr_values)\n",
    "psnr_values = sort(psnr_values)\n",
    "psnr_values = psnr_values[:]\n",
    "print(len(psnr_values))\n",
    "avg_psnr = psnr_values.sum()/len(psnr_values)\n",
    "# avg_ssim = ssim_values/len(test_loader)\n",
    "\n",
    "print(f\"Evaluation Results:\")\n",
    "print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "# print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "\n",
    "with open(f'{results_dir}/metrics.txt', 'a') as f:\n",
    "    f.write(f\"Model: {model_path}\\n\")\n",
    "    f.write(f\"Average PSNR: {avg_psnr:.2f} dB\\n\")\n",
    "    # f.write(f\"Average SSIM: {avg_ssim:.4f}\\n\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_without_CA'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 27\u001B[0m\n\u001B[0;32m     22\u001B[0m model \u001B[38;5;241m=\u001B[39m SpectralTransformer()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m#model = NewModel().to(device)\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#model = NewBigModel().to(device)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#checkpoint = torch.load(model_path, map_location=device)\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m#model.load_state_dict(checkpoint['model_state_dict'])\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     30\u001B[0m psnr_values \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\PycharmProjects\\Underwater-Image-Restoration\\.venv\\lib\\site-packages\\torch\\serialization.py:1471\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1469\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1470\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1471\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[0;32m   1472\u001B[0m             opened_zipfile,\n\u001B[0;32m   1473\u001B[0m             map_location,\n\u001B[0;32m   1474\u001B[0m             pickle_module,\n\u001B[0;32m   1475\u001B[0m             overall_storage\u001B[38;5;241m=\u001B[39moverall_storage,\n\u001B[0;32m   1476\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[0;32m   1477\u001B[0m         )\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[0;32m   1479\u001B[0m     f_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Underwater-Image-Restoration\\.venv\\lib\\site-packages\\torch\\serialization.py:1964\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1962\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m _serialization_tls\n\u001B[0;32m   1963\u001B[0m _serialization_tls\u001B[38;5;241m.\u001B[39mmap_location \u001B[38;5;241m=\u001B[39m map_location\n\u001B[1;32m-> 1964\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1965\u001B[0m _serialization_tls\u001B[38;5;241m.\u001B[39mmap_location \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1967\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Underwater-Image-Restoration\\.venv\\lib\\site-packages\\torch\\serialization.py:1953\u001B[0m, in \u001B[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001B[1;34m(self, mod_name, name)\u001B[0m\n\u001B[0;32m   1951\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1952\u001B[0m mod_name \u001B[38;5;241m=\u001B[39m load_module_mapping\u001B[38;5;241m.\u001B[39mget(mod_name, mod_name)\n\u001B[1;32m-> 1953\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'model_without_CA'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T12:33:51.014736Z",
     "start_time": "2025-05-10T12:33:50.972215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "def torchPSNR(tar_img, prd_img):\n",
    "    imdff = torch.clamp(prd_img, 0, 1) - torch.clamp(tar_img, 0, 1)\n",
    "    rmse = (imdff**2).mean().sqrt()\n",
    "    ps = 20*torch.log10(1/rmse)\n",
    "    return ps\n",
    "\n",
    "def torchSSIM(tar_img, prd_img):\n",
    "    return ssim(tar_img, prd_img, data_range=1.0, size_average=True)\n",
    "\n"
   ],
   "id": "92f75947527f5181",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Models.SpectralTransformer import SpectralTransformer\n",
    "\n",
    "model = SpectralTransformer()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
